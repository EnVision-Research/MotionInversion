{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'motion_activation_fn': 'geglu', 'motion_attention_bias': False, 'motion_cross_attention_dim': None} were passed to MotionAdapter, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http_proxy: http://oversea-squid5.sgp.txyun:11080\n",
      "https_proxy: http://oversea-squid5.sgp.txyun:11080\n",
      "no_proxy: localhost,127.0.0.1,localaddress,localdomain.com,internal,corp.kuaishou.com,test.gifshow.com,staging.kuaishou.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 5/5 [00:33<00:00,  6.61s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from pipelines.pipeline_animatediff import *\n",
    "from diffusers.schedulers import DDIMInverseScheduler\n",
    "from diffusers.utils import export_to_gif, export_to_video, load_image\n",
    "from utils.attn_utils import *\n",
    "\n",
    "# Set proxy environment variables\n",
    "os.environ['http_proxy'] = 'http://oversea-squid5.sgp.txyun:11080'\n",
    "os.environ['https_proxy'] = 'http://oversea-squid5.sgp.txyun:11080'\n",
    "os.environ['no_proxy'] = 'localhost,127.0.0.1,localaddress,localdomain.com,internal,corp.kuaishou.com,test.gifshow.com,staging.kuaishou.com'\n",
    "\n",
    "# Verify the setting\n",
    "print(\"http_proxy:\", os.environ.get('http_proxy'))\n",
    "print(\"https_proxy:\", os.environ.get('https_proxy'))\n",
    "print(\"no_proxy:\", os.environ.get('no_proxy'))\n",
    "\n",
    "\n",
    "# Load the motion adapter\n",
    "adapter = MotionAdapter.from_pretrained(\"/home/wangluozhou/projects/AnimateDiff/models/Motion_Module/animatediff-motion-adapter-v1-5-2\", torch_dtype=torch.float32)\n",
    "# Load the controlnet\n",
    "# controlnet = ControlNetModel.from_pretrained('/home/wangluozhou/pretrained_models/sd-controlnet-depth', torch_dtype=torch.float16)\n",
    "# load SD 1.5 based finetuned model\n",
    "model_id = \"/home/wangluozhou/pretrained_models/zeroscope_v2_576w\"\n",
    "pipe = VideoDiffPipeline.from_pretrained(\n",
    "    model_id, \n",
    "    motion_adapter=None, \n",
    "    controlnet=None, \n",
    "    use_motion_mid_block=True,\n",
    "    torch_dtype=torch.float32\n",
    ")\n",
    "\n",
    "pipe.scheduler = DDIMScheduler.from_pretrained(model_id, subfolder='scheduler')\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# enable memory savings\n",
    "pipe.enable_vae_slicing()\n",
    "\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pipelines.pipeline_animatediff import *\n",
    "from diffusers.schedulers import DDIMInverseScheduler\n",
    "from diffusers.utils import export_to_gif, export_to_video, load_image\n",
    "from utils.attn_utils import *\n",
    "\n",
    "model_id = \"/home/wangluozhou/pretrained_models/Realistic_Vision_V6.0_B1_noVAE\"\n",
    "\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\n",
    "    model_id, subfolder=\"tokenizer\", revision=None)\n",
    "    \n",
    "motion_adapter = MotionAdapter.from_pretrained(\n",
    "    \"/home/wangluozhou/projects/AnimateDiff/models/Motion_Module/animatediff-motion-adapter-v1-5-2\",\n",
    "    variant=\"fp16\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\n",
    "    model_id, subfolder=\"text_encoder\", revision=None\n",
    ")\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    model_id, subfolder=\"vae\", revision=None)\n",
    "\n",
    "# unet = UNet2DConditionModel.from_pretrained(\n",
    "#     model_id,\n",
    "#     subfolder=\"unet\",\n",
    "#     low_cpu_mem_usage=True,\n",
    "# )\n",
    "unet = UNetMotionModel.from_unet2d(UNet2DConditionModel.from_pretrained(\n",
    "    model_id,\n",
    "    subfolder=\"unet\",\n",
    "    low_cpu_mem_usage=True,\n",
    "), motion_adapter)\n",
    "\n",
    "\n",
    "pipe = AnimateDiffPipeline.from_pretrained(\n",
    "    model_id, \n",
    "    motion_adapter=None, \n",
    "    controlnet=None, \n",
    "    use_motion_mid_block=True,\n",
    "    use_safetensors=True,\n",
    "    torch_dtype=torch.float16)\n",
    "pipe.unet = unet.to(device='cuda',dtype=torch.float16)\n",
    "# pipe.scheduler = DDIMScheduler.from_pretrained(model_id, subfolder='scheduler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.config['use_motion_mid_block']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text-to-Video Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    prompt=(\n",
    "        # \"a man\"\n",
    "        \"orange sky, warm lighting, fishing boats, ocean waves seagulls, \"\n",
    "        \"rippling water, wharf, silhouette, serene atmosphere, dusk, evening glow, \"\n",
    "        \"golden hour, coastal landscape, seaside scenery\"\n",
    "    ),\n",
    "    negative_prompt=\"bad quality, worse quality\",\n",
    "    height=256,\n",
    "    width=256,\n",
    "    num_frames=16,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=25,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(42),\n",
    ")\n",
    "frames = output.frames[0]\n",
    "export_to_gif(frames, \"animation_16.gif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Video Editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load Source Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load video and into frames\n",
    "frames = load_video('/home/wangluozhou/projects/VideoDiffusion_Playground/resources/locomotive_run.mp4')\n",
    "\n",
    "# 1. encode frames into batch of latents\n",
    "latents_frames = pipe.encode_frames(frames, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.1 Inverse with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_latent, _ = pipe.add_noise_to_latents(\n",
    "    init_latents=latents_frames, \n",
    "    strength=0.8,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(42),\n",
    "    num_inference_steps=25,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 Inverse with DDIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler = DDIMInverseScheduler.from_pretrained(model_id, subfolder='scheduler')\n",
    "inv_latent = pipe(\n",
    "        prompt=\"\", \n",
    "        negative_prompt=\"\",\n",
    "        num_frames=16,\n",
    "        guidance_scale=7.5,\n",
    "        output_type='latent', \n",
    "        num_inference_steps=25,\n",
    "        strength=0.8, \n",
    "        latents=latents_frames,\n",
    "        inverse=True,\n",
    "    ).frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler = DDIMScheduler.from_pretrained(model_id, subfolder='scheduler')\n",
    "output = pipe(\n",
    "    prompt=\"a pretty girl, white singlet, dark pants, on the stage\",\n",
    "    negative_prompt=\"\",\n",
    "    num_frames=16,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=25,\n",
    "    latents=inv_latent,\n",
    "    # frames=frames_controlnet,\n",
    "    strength=0.8,\n",
    "    # generator=torch.Generator(\"cpu\").manual_seed(42),\n",
    ")\n",
    "frames = output.frames[0]\n",
    "export_to_gif(frames, \"/home/wangluozhou/projects/VideoDiffusion_Playground/resources/Human/sample_3_edit.gif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Text-to-Video Generation with ControlNets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Load Control Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from controlnet_aux.processor import Processor\n",
    "processor = Processor(\"depth_midas\")\n",
    "\n",
    "# load video and into frames\n",
    "frames = load_video('/home/wangluozhou/projects/VideoDiffusion_Playground/resources/Animals/sample_0_src.mp4')\n",
    "\n",
    "frames_controlnet = []\n",
    "for frame in frames:\n",
    "    frames_controlnet.append(processor(frame, to_pil=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[0].size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler = DDIMScheduler.from_pretrained(model_id, subfolder='scheduler')\n",
    "output = pipe(\n",
    "    prompt=\"a sea lion, lying on the ice, winter, snow\",\n",
    "    negative_prompt=\"\",\n",
    "    num_frames=16,\n",
    "    height=320,\n",
    "    width=512,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=25,\n",
    "    frames_controlnet=frames_controlnet,\n",
    "    strength=1.0,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(42),\n",
    ")\n",
    "frames = output.frames[0]\n",
    "export_to_gif(frames, \"/home/wangluozhou/projects/VideoDiffusion_Playground/resources/Animals/sample_0_edit_2.gif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Image-to-Video Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_curve_tensor(max_value, min_value, length, frames, strategy='linear'):\n",
    "    \"\"\"\n",
    "    Build a curve based on the given strategy and return it as a PyTorch tensor.\n",
    "    The curve starts from the min_value and increases to the max_value.\n",
    "\n",
    "    Parameters:\n",
    "    max_value (float): The maximum value of the curve.\n",
    "    min_value (float): The minimum value of the curve.\n",
    "    length (int): The length over which the curve changes from min to max.\n",
    "    frames (int): The total number of frames in the curve.\n",
    "    strategy (str): The strategy for building the curve. Options: 'linear', 'exponential', 'logarithmic'.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: A tensor representing the curve.\n",
    "    \"\"\"\n",
    "\n",
    "    if strategy == 'linear':\n",
    "        # Linear increase from min_value to max_value over 'length' frames, then constant\n",
    "        curve = np.linspace(max_value, min_value, length)\n",
    "        curve = np.pad(curve, (0, frames - length), mode='constant', constant_values=min_value)\n",
    "\n",
    "    elif strategy == 'exponential':\n",
    "        # Exponential increase from min_value to max_value\n",
    "        curve = np.geomspace(max_value, min_value, length)\n",
    "        curve = np.pad(curve, (0, frames - length), mode='constant', constant_values=min_value)\n",
    "\n",
    "    elif strategy == 'logarithmic':\n",
    "        # Logarithmic increase from min_value to max_value\n",
    "        log_space = np.linspace(1, length + 1, length)\n",
    "        curve = (np.log(log_space) / np.log(length + 1)) * (min_value - max_value) + min_value\n",
    "        curve = np.pad(curve, (0, frames - length), mode='constant', constant_values=min_value)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown strategy: Choose from 'linear', 'exponential', 'logarithmic'\")\n",
    "\n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    return torch.from_numpy(curve)\n",
    "\n",
    "# Example usage with reversed curve\n",
    "# curve_tensor_reversed = build_curve_tensor_reversed(1, 0.5, 3, 16, strategy='linear')\n",
    "# curve_tensor_reversed  # Display the generated tensor curve\n",
    "# Result\n",
    "# tensor([0.5000, 0.7500, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
    "#         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
    "#        dtype=torch.float64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 load source image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from video\n",
    "frames = load_video('/home/wangluozhou/projects/VideoDiffusion_Playground/resources/sample_5_src.mp4')\n",
    "frames_inpaint = [frames[0]] * 16\n",
    "latents_frames_inpaint = pipe.encode_frames(frames_inpaint, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from image\n",
    "frames = load_image('/home/wangluozhou/projects/VideoDiffusion_Playground/resources/4.png')\n",
    "frames_inpaint = [frames] * 16\n",
    "latents_frames_inpaint = pipe.encode_frames(frames_inpaint, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Prepare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare inital latents\n",
    "latents = pipe.prepare_latents(\n",
    "    batch_size=1,\n",
    "    num_channels_latents=4,\n",
    "    num_frames=16,\n",
    "    height=frames_inpaint[0].size[1],\n",
    "    width=frames_inpaint[0].size[0],\n",
    "    dtype=torch.float16,\n",
    "    device=device,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(42)\n",
    ")\n",
    "\n",
    "mask_inpaint = torch.zeros_like(latents_frames_inpaint)\n",
    "\n",
    "# # Values to assign along the frames dimension\n",
    "# frame_values = build_curve_tensor(\n",
    "#     max_value=1.0,\n",
    "#     min_value=0.5,\n",
    "#     length=8,\n",
    "#     frames=16,\n",
    "# )\n",
    "# frame_values[-1]=1\n",
    "\n",
    "mask_inpaint[:,:,0,:,:]=1\n",
    "mask_inpaint[:,:,-1,:,:]=1\n",
    "\n",
    "# # Assign the values to each frame in the mask\n",
    "# for i, value in enumerate(frame_values):\n",
    "#     mask_inpaint[:, :, i, :, :] = value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler = DDIMScheduler.from_pretrained(model_id, subfolder='scheduler')\n",
    "output = pipe(\n",
    "    prompt=\"Sunny seaside with blue sky\",\n",
    "    negative_prompt=\"\",\n",
    "    num_frames=16,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=25,\n",
    "    latents=latents,\n",
    "    frames_inpaint=latents_frames_inpaint,\n",
    "    noise_inpaint=latents,\n",
    "    mask_inpaint=mask_inpaint,\n",
    "    strength=1.0,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(42),\n",
    ")\n",
    "frames = output.frames[0]\n",
    "export_to_gif(frames, \"sample_4_animation.gif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Image Animation - Noise Rectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from image\n",
    "frames = load_image('/home/wangluozhou/projects/VideoDiffusion_Playground/resources/4.png')\n",
    "frames_inpaint = [frames] * 16\n",
    "latents_frames_inpaint = pipe.encode_frames(frames_inpaint, device=device)\n",
    "\n",
    "generator = torch.Generator(\"cpu\").manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_latent, init_noise = pipe.add_noise_to_latents(\n",
    "    init_latents=latents_frames_inpaint, \n",
    "    strength=1.0,\n",
    "    generator=generator,\n",
    "    num_inference_steps=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inpaint = torch.ones_like(inv_latent)\n",
    "\n",
    "# Values to assign along the frames dimension\n",
    "frame_values, curves = build_curve_tensor(\n",
    "    max_value=1.0,\n",
    "    min_value=0.5,\n",
    "    length=8,\n",
    "    frames=16,\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "# Assign the values to each frame in the mask\n",
    "for i, value in enumerate(frame_values):\n",
    "    mask_inpaint[:, :, i, :, :] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler = DDIMScheduler.from_pretrained(model_id, subfolder='scheduler')\n",
    "output = pipe(\n",
    "    prompt=\"Sunny seaside with blue sky\",\n",
    "    negative_prompt=\"\",\n",
    "    num_frames=16,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=25,\n",
    "    # rect_scheduled_sampling_beta=0.6,\n",
    "    latents=inv_latent,\n",
    "    # noise_rect=init_noise,\n",
    "    # mask_inpaint=mask_inpaint,\n",
    "    strength=1.0,\n",
    "    generator=generator,\n",
    ")\n",
    "frames = output.frames[0]\n",
    "export_to_gif(frames, \"sample_4_animation_noise1.0.gif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Video Outpainting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Load source video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from video\n",
    "frames_inpaint = load_video('/home/wangluozhou/projects/VideoDiffusion_Playground/resources/Outpainting/sample_7_src.mp4')\n",
    "\n",
    "latents_frames_inpaint = pipe.encode_frames(frames_inpaint, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_inpaint[0].size[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Prepare noise and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare inital latents\n",
    "latents = pipe.prepare_latents(\n",
    "    batch_size=1,\n",
    "    num_channels_latents=4,\n",
    "    num_frames=16,\n",
    "    height=frames_inpaint[0].size[1],\n",
    "    width=frames_inpaint[0].size[0],\n",
    "    dtype=torch.float16,\n",
    "    device=device,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w/o motion adapter\n",
    "\n",
    "# [bs, channels, frames, height, width] -> -> [bs * frames, channels, height, width]\n",
    "frames_inpaint = frames_inpaint.permute(0,2,1,3,4).reshape((latents.shape[0] * num_frames, -1) + frames_inpaint.shape[3:])\n",
    "\n",
    "# [bs * frames, channels, height, width]\n",
    "mask_inpaint = torch.zeros_like(frames_inpaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with motion adapter\n",
    "# [bs, channels frames, height, width]\n",
    "\n",
    "mask_inpaint = torch.ones_like(latents_frames_inpaint)\n",
    "mask_inpaint[:, :, :, mask_inpaint.shape[3]//4:mask_inpaint.shape[3]//4 * 3, :] = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler = DDIMScheduler.from_pretrained(model_id, subfolder='scheduler')\n",
    "output = pipe(\n",
    "    prompt=\"a pretty girl, grey t-shirt\",\n",
    "    negative_prompt=\"\",\n",
    "    num_frames=16,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=25,\n",
    "    latents=latents,\n",
    "    frames_inpaint=latents_frames_inpaint,\n",
    "    noise_inpaint=latents,\n",
    "    mask_inpaint=mask_inpaint,\n",
    "    strength=1.0,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(42),\n",
    ")\n",
    "frames = output.frames[0]\n",
    "export_to_gif(frames, \"/home/wangluozhou/projects/VideoDiffusion_Playground/resources/Outpainting/sample_7_edit.gif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Frames Attention Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Prepare Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = pipe.prepare_latents(\n",
    "    batch_size=1,\n",
    "    num_channels_latents=4,\n",
    "    num_frames=16,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    dtype=torch.float16,\n",
    "    device=device,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_2 = pipe.prepare_latents(\n",
    "    batch_size=1,\n",
    "    num_channels_latents=4,\n",
    "    num_frames=8,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    dtype=torch.float16,\n",
    "    device=device,\n",
    "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
    ")\n",
    "latents = torch.cat([latents, latents_2], dim=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Prepare Attention Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = AttentionStore()\n",
    "register_attention_control(pipe, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.target_keys = ('down_self',)\n",
    "controller.target_resolutions = [16]\n",
    "# prompts = [\"a man is surfing\", \"a cat is climbing\", \"a dog is running\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controller.reset()\n",
    "output = pipe(\n",
    "    prompt=[\n",
    "            (\n",
    "                \"a spiderman is surfing\"\n",
    "            ),\n",
    "            # (\n",
    "            #     \"masterpiece, bestquality, highlydetailed, ultradetailed, sunset, \"\n",
    "            #     \"orange sky, warm lighting, fishing boats, ocean waves seagulls, \"\n",
    "            #     \"rippling water, wharf, silhouette, serene atmosphere, dusk, evening glow, \"\n",
    "            #     \"golden hour, coastal landscape, seaside scenery\"\n",
    "            # )\n",
    "            # (\n",
    "            #     \"a man is surfing\"\n",
    "            # )\n",
    "        ],\n",
    "    negative_prompt=[\n",
    "        \"bad quality, worse quality\",\n",
    "        # \"bad quality, worse quality\"\n",
    "        ],\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=25,\n",
    "    latents=latents\n",
    ")\n",
    "# frames = output.frames[1]\n",
    "# export_to_gif(frames, \"animation_24_animatediff.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_gif(output.frames[1], \"outputs/animation_16_ad_seed42_bs1_attn_down_16_32.gif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.attention_store['down_self'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_average_map(controller.attention_store['down_self'], frames=16, pixel_size=5, reduction='spatial')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_image_grid(controller.attention_store['up_self'], frames=16, pixel_size=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Batch Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "import random\n",
    "\n",
    "def all_combinations(lst):\n",
    "    return chain(*map(lambda x: combinations(lst, x), range(0, len(lst) + 1)))\n",
    "\n",
    "controller_target_keys = ['down_self', 'mid_self', 'up_self']\n",
    "controller_target_resolutions = [16, 32, 64, 128]\n",
    "prompts = [\"a man is surfing\", \"a cat is climbing\", \"a dog is running\"]\n",
    "\n",
    "key_combinations = list(all_combinations(controller_target_keys))\n",
    "resolution_combinations = [controller_target_resolutions[:i + 1] for i in range(len(controller_target_resolutions))]\n",
    "\n",
    "parameter_combinations = []\n",
    "for keys in key_combinations:\n",
    "    if not keys:\n",
    "        resolutions_combinations = [[]]  # Skip resolution combinations if no key is selected\n",
    "    else:\n",
    "        resolutions_combinations = resolution_combinations\n",
    "\n",
    "    for resolutions in resolutions_combinations:\n",
    "        for prompt in prompts:\n",
    "            combination = (keys, resolutions, prompt)\n",
    "            parameter_combinations.append(combination)\n",
    "\n",
    "def generate_name(combination):\n",
    "    keys, resolutions, prompt = combination\n",
    "    keys_name = '_'.join(keys) if keys else 'nokey'\n",
    "    resolutions_name = '_'.join(map(str, resolutions)) if keys else 'noresolution'\n",
    "    prompt_name = prompt.replace(' ', '_')\n",
    "    return f\"{keys_name}_{resolutions_name}_{prompt_name}\"\n",
    "\n",
    "# output_names = [generate_name(combination) for combination in parameter_combinations]\n",
    "\n",
    "# # Example output names\n",
    "# print(output_names[:5])  # Displaying first 5 names for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combination in parameter_combinations:\n",
    "    (keys, resolutions, prompt) = combination\n",
    "    controller.target_keys = keys\n",
    "    controller.target_resolutions = resolutions\n",
    "    \n",
    "\n",
    "    output = pipe(\n",
    "        prompt=[\n",
    "                (\n",
    "                    \"a spiderman is surfing\"\n",
    "                ),\n",
    "                # (\n",
    "                #     \"masterpiece, bestquality, highlydetailed, ultradetailed, sunset, \"\n",
    "                #     \"orange sky, warm lighting, fishing boats, ocean waves seagulls, \"\n",
    "                #     \"rippling water, wharf, silhouette, serene atmosphere, dusk, evening glow, \"\n",
    "                #     \"golden hour, coastal landscape, seaside scenery\"\n",
    "                # )\n",
    "                (\n",
    "                    prompt\n",
    "                )\n",
    "            ],\n",
    "        negative_prompt=[\n",
    "            \"bad quality, worse quality\",\n",
    "            \"bad quality, worse quality\"\n",
    "            ],\n",
    "        guidance_scale=7.5,\n",
    "        num_inference_steps=25,\n",
    "        latents=latents\n",
    "    )\n",
    "    export_to_gif(output.frames[1], f\"outputs/{generate_name(combination)}.gif\")\n",
    "    controller.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. PE Inversion Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pe_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_positional_embedding_unet3d(pipe.unet, target_size=[320, 640, 1280], target_module=['down','mid','up'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_path = '/home/wangluozhou/projects/VideoDiffusion_Playground/outputs/size_1280_unet3d/pos_embed.pt'\n",
    "load_positional_embedding(pipe.unet, pe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangluozhou/projects/VideoDiffusion_Playground/pipelines/pipeline_animatediff.py:743: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet3DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet3DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  num_channels_latents = self.unet.in_channels\n"
     ]
    }
   ],
   "source": [
    "pipe.init_filter(\n",
    "    video_length=16,\n",
    "    height=320,\n",
    "    width=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_frames = load_video('/home/wangluozhou/projects/VideoDiffusion_Playground/resources/Objects/sample_0_src.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_frames = pipe.encode_frames(src_frames, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 16, 40, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latents_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:05<00:00,  1.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/wangluozhou/projects/VideoDiffusion_Playground/outputs/test/animation.gif'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pipe(\n",
    "    prompt=(\n",
    "        \"Amazing quality, masterpiece, a man rides a bicycle in the snow field\"\n",
    "        # \"orange sky, warm lighting, fishing boats, ocean waves seagulls, \"\n",
    "        # \"rippling water, wharf, silhouette, serene atmosphere, dusk, evening glow, \"\n",
    "        # \"golden hour, coastal landscape, seaside scenery\"\n",
    "    ),\n",
    "    negative_prompt=\"bad quality, distortions, unrealistic, distorted image, watermark, signature\",\n",
    "    height=320,\n",
    "    width=512,\n",
    "    num_frames=16,\n",
    "    guidance_scale=10,\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.Generator(\"cuda\").manual_seed(0),\n",
    "    freeinit=True,\n",
    "    frames_video=latents_frames,\n",
    ")\n",
    "frames = output.frames[0]\n",
    "export_to_gif(frames, \"/home/wangluozhou/projects/VideoDiffusion_Playground/outputs/test/animation.gif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Mischelleos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pipelines.pipeline_animatediff import *\n",
    "from diffusers.schedulers import DDIMInverseScheduler\n",
    "from diffusers.utils import export_to_gif, export_to_video, load_image\n",
    "from utils.attn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = load_video('/home/wangluozhou/projects/VideoDiffusion_Playground/resources/dog_jump_water.mp4')\n",
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for idx, frame in enumerate(frames):\n",
    "    frame.save(os.path.join('/home/wangluozhou/projects/diffusion-motion-transfer/data/car',f'{str(idx).zfill(4)}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
